{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a549_df = pd.read_csv('../SGNex_A549_directRNA_replicate5_run1_data.csv')\n",
    "\n",
    "mcf7_df = pd.read_csv('../SGNex_MCF7_directRNA_replicate3_run1_data.csv')\n",
    "\n",
    "k562_df = pd.read_csv('../SGNex_K562_directRNA_replicate4_run1_data.csv')\n",
    "\n",
    "hepg2_df = pd.read_csv('../SGNex_HepG2_directRNA_replicate6_run1_data.csv')\n",
    "\n",
    "hct116_df = pd.read_csv('../SGNex_Hct116_directRNA_replicate3_run1_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_process_df(df):\n",
    "    # Step 1: Drop the unnecessary columns\n",
    "    df = df.drop(columns=[\"ori_nucleotide\", \"fivemer_neg_1\", \"fivemer_0\", \"fivemer_1\"])\n",
    "\n",
    "    # Step 2: Group by 'transcript_id' and 'transcript_position' and calculate the necessary aggregations\n",
    "    averaged_df = df.groupby(['transcript_id', 'transcript_position']).agg({\n",
    "        'dwelling_time_neg_1': ['mean', 'min', 'max', 'median'],\n",
    "        'dwelling_time_0': ['mean', 'min', 'max', 'median'],\n",
    "        'dwelling_time_1': ['mean', 'min', 'max', 'median'],\n",
    "        'mean_neg_1': ['mean', 'min', 'max', 'median'],\n",
    "        'mean_0': ['mean', 'min', 'max', 'median'],\n",
    "        'mean_1': ['mean', 'min', 'max', 'median'],\n",
    "        'sd_neg_1': ['mean', 'min', 'max', 'median'],\n",
    "        'sd_0': ['mean', 'min', 'max', 'median'],\n",
    "        'sd_1': ['mean', 'min', 'max', 'median']\n",
    "    }).reset_index()\n",
    "\n",
    "    # Step 3: Rename columns to a consistent format\n",
    "    averaged_df.columns = [\n",
    "        f'{col[0]}_{col[1]}' if col[1] else col[0]  # Join column names with '_'\n",
    "        for col in averaged_df.columns\n",
    "    ]\n",
    "\n",
    "    # Step 4: Add rolling differences for 'mean' values\n",
    "    def add_rolling(df):\n",
    "        # Define the pairs of columns to calculate differences for each metric\n",
    "        calculations = {\n",
    "            'dwelling_time': [('dwelling_time_neg_1_mean', 'dwelling_time_0_mean'), \n",
    "                              ('dwelling_time_0_mean', 'dwelling_time_1_mean')],\n",
    "            'mean': [('mean_neg_1_mean', 'mean_0_mean'), \n",
    "                     ('mean_0_mean', 'mean_1_mean')],\n",
    "            'sd': [('sd_neg_1_mean', 'sd_0_mean'), \n",
    "                   ('sd_0_mean', 'sd_1_mean')]\n",
    "        }\n",
    "\n",
    "        for metric, pairs in calculations.items():\n",
    "            for first, second in pairs:\n",
    "                # Create a new column with a unique name for the difference\n",
    "                df[f'{metric}_diff_{first}_{second}'] = df[first] - df[second]\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Step 5: Apply the rolling difference function to the averaged DataFrame\n",
    "    averaged_df = add_rolling(averaged_df)\n",
    "\n",
    "    return averaged_df\n",
    "\n",
    "# Example of how to use this function for multiple dataframes\n",
    "# cleaned_dfs = [clean_and_process_df(df) for df in list_of_dfs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a549_cleaned = clean_and_process_df(a549_df)\n",
    "mcf7_cleaned = clean_and_process_df(mcf7_df)\n",
    "k562_cleaned = clean_and_process_df(k562_df)\n",
    "hepg2_cleaned = clean_and_process_df(hepg2_df)\n",
    "hct116_cleaned = clean_and_process_df(hct116_df)\n",
    "\n",
    "# Add label columns\n",
    "a549_cleaned['source'] = 'A549'\n",
    "mcf7_cleaned['source'] = 'MCF7'\n",
    "k562_cleaned['source'] = 'K562'\n",
    "hepg2_cleaned['source'] = 'HepG2'\n",
    "hct116_cleaned['source'] = 'Hct116'\n",
    "\n",
    "# Combine all the cleaned dataframes into one mega dataframe\n",
    "mega_df = pd.concat([a549_cleaned, mcf7_cleaned, k562_cleaned, hepg2_cleaned, hct116_cleaned], axis=0)\n",
    "\n",
    "# Reset index after concatenation\n",
    "mega_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "excluded_columns = ['transcript_id', 'transcript_position', 'source']\n",
    "\n",
    "# List of columns to scale\n",
    "scaled_columns = [col for col in mega_df.columns if col not in excluded_columns]\n",
    "\n",
    "# Scale the selected columns\n",
    "mega_df[scaled_columns] = scaler.fit_transform(mega_df[scaled_columns])\n",
    "# Check the modified DataFrame\n",
    "mega_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df_filtered = mega_df[['sd_0_mean',\n",
    " 'mean_0_mean',\n",
    " 'mean_diff_mean_0_mean_mean_1_mean',\n",
    " 'sd_0_median',\n",
    " 'mean_0_median',\n",
    " 'mean_diff_mean_neg_1_mean_mean_0_mean',\n",
    " 'mean_1_mean',\n",
    " 'sd_0_min',\n",
    " 'mean_neg_1_mean',\n",
    " 'sd_diff_sd_0_mean_sd_1_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the model\n",
    "model = tf.keras.models.load_model('../cnn_selected.keras')\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "X_test = mega_df_filtered.values  # Convert to NumPy array if it's a DataFrame\n",
    "\n",
    "# Step 3: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Step 4: Convert probabilities to binary outcomes\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Ensure that binary_predictions is a 1D array to match the DataFrame rows\n",
    "binary_predictions = binary_predictions.flatten()\n",
    "\n",
    "# Use .loc to assign predictions safely\n",
    "mega_df.loc[:, 'predictions'] = binary_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale the selected columns (returning to original values)\n",
    "mega_df[scaled_columns] = scaler.inverse_transform(mega_df[scaled_columns])\n",
    "\n",
    "# Check the unstandardized DataFrame\n",
    "print(mega_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mega_df.to_csv('../results_mega_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/rachels/Desktop/NUS/Y4/DSA4262/Team_Project/data/Task 2/merged/results_mega_df.csv', sep=',')\n",
    "df['status'] = df['predictions'].apply(lambda x: 'modified' if x == 1 else \"unmodified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison across modified/unmodified for means across cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# List of columns to plot\n",
    "columns = [\"mean_neg_1_mean\", 'mean_0_mean', 'mean_1_mean']\n",
    "titles = ['Mean_neg_1', \n",
    "          'Mean_0', \n",
    "          'Mean_1']\n",
    "\n",
    "# Loop through each axis and column to create boxplots\n",
    "for ax, col, title in zip(axes, columns, titles):\n",
    "    sns.violinplot(x='source', y=col, hue='status', data=df, ax=ax, palette=['lightgreen', 'lightblue'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Cell Line')\n",
    "    ax.set_ylabel('Mean Value')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "plt.suptitle('Comparison of Modifications across Cell Lines', fontsize=20, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison across modified/unmodified for sd across cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# List of columns to plot\n",
    "columns = [\"sd_neg_1_mean\", 'sd_0_mean', 'sd_1_mean']\n",
    "titles = ['sd_neg_1', \n",
    "          'sd_0', \n",
    "          'sd_1']\n",
    "\n",
    "# Loop through each axis and column to create boxplots\n",
    "for ax, col, title in zip(axes, columns, titles):\n",
    "    sns.violinplot(x='source', y=col, hue='status', data=df, ax=ax, palette=['lightgreen', 'lightblue'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.set_xlabel('Cell Line')\n",
    "    ax.set_ylabel('SD Value')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "plt.suptitle('Comparison of Modifications across Cell Lines', fontsize=20, fontweight='bold', y=1.01)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
